{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 3 : Buzz Prediction on Twitter\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 2.\n",
    "- Run all the models only on 10% data. Use code given in Project 2 for sampling.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 2 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 2, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply four voting classifiers - two with hard voting and two with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 2 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 2, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project3_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project3_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project3_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnnames = ['NCD_0',\n",
    "'NCD_1',\n",
    "'NCD_2',\n",
    "'NCD_3',\n",
    "'NCD_4',\n",
    "'NCD_5',\n",
    "'NCD_6',\n",
    "'AI_0',\n",
    "'AI_1',\n",
    "'AI_2',\n",
    "'AI_3',\n",
    "'AI_4',\n",
    "'AI_5',\n",
    "'AI_6',\n",
    "'AS(NA)_0',\n",
    "'AS(NA)_1',\n",
    "'AS(NA)_2',\n",
    "'AS(NA)_3',\n",
    "'AS(NA)_4',\n",
    "'AS(NA)_5',\n",
    "'AS(NA)_6',\n",
    "'BL_0',\n",
    "'BL_1',\n",
    "'BL_2',\n",
    "'BL_3',\n",
    "'BL_4',\n",
    "'BL_5',\n",
    "'BL_6',\n",
    "'NAC_0',\n",
    "'NAC_1',\n",
    "'NAC_2',\n",
    "'NAC_3',\n",
    "'NAC_4',\n",
    "'NAC_5',\n",
    "'NAC_6',\n",
    "'AS(NAC)_0',\n",
    "'AS(NAC)_1',\n",
    "'AS(NAC)_2',\n",
    "'AS(NAC)_3',\n",
    "'AS(NAC)_4',\n",
    "'AS(NAC)_5',\n",
    "'AS(NAC)_6',\n",
    "'CS_0',\n",
    "'CS_1',\n",
    "'CS_2',\n",
    "'CS_3',\n",
    "'CS_4',\n",
    "'CS_5',\n",
    "'CS_6',\n",
    "'AT_0',\n",
    "'AT_1',\n",
    "'AT_2',\n",
    "'AT_3',\n",
    "'AT_4',\n",
    "'AT_5',\n",
    "'AT_6',\n",
    "'NA_0',\n",
    "'NA_1',\n",
    "'NA_2',\n",
    "'NA_3',\n",
    "'NA_4',\n",
    "'NA_5',\n",
    "'NA_6',\n",
    "'ADL_0',\n",
    "'ADL_1',\n",
    "'ADL_2',\n",
    "'ADL_3',\n",
    "'ADL_4',\n",
    "'ADL_5',\n",
    "'ADL_6',\n",
    "'NAD_0',\n",
    "'NAD_1',\n",
    "'NAD_2',\n",
    "'NAD_3',\n",
    "'NAD_4',\n",
    "'NAD_5',\n",
    "'NAD_6',\n",
    "'NAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>1.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>...</th>\n",
       "      <th>1.000000.14</th>\n",
       "      <th>1.000000.15</th>\n",
       "      <th>0.12</th>\n",
       "      <th>2.2</th>\n",
       "      <th>0.13</th>\n",
       "      <th>0.14</th>\n",
       "      <th>1.14</th>\n",
       "      <th>1.15</th>\n",
       "      <th>1.16</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583219</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583220</th>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583221</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583222</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583223</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583224</th>\n",
       "      <td>435</td>\n",
       "      <td>349</td>\n",
       "      <td>386</td>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>231</td>\n",
       "      <td>173</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>435</td>\n",
       "      <td>349</td>\n",
       "      <td>386</td>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583225</th>\n",
       "      <td>349</td>\n",
       "      <td>386</td>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>173</td>\n",
       "      <td>182</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>349</td>\n",
       "      <td>386</td>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583226</th>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>419</td>\n",
       "      <td>747</td>\n",
       "      <td>173</td>\n",
       "      <td>117</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>317</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>419</td>\n",
       "      <td>747</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583227</th>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>419</td>\n",
       "      <td>747</td>\n",
       "      <td>363</td>\n",
       "      <td>117</td>\n",
       "      <td>217</td>\n",
       "      <td>261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>325</td>\n",
       "      <td>441</td>\n",
       "      <td>511</td>\n",
       "      <td>417</td>\n",
       "      <td>419</td>\n",
       "      <td>747</td>\n",
       "      <td>363</td>\n",
       "      <td>371.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583228</th>\n",
       "      <td>363</td>\n",
       "      <td>329</td>\n",
       "      <td>414</td>\n",
       "      <td>514</td>\n",
       "      <td>533</td>\n",
       "      <td>486</td>\n",
       "      <td>417</td>\n",
       "      <td>168</td>\n",
       "      <td>167</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>363</td>\n",
       "      <td>329</td>\n",
       "      <td>414</td>\n",
       "      <td>514</td>\n",
       "      <td>533</td>\n",
       "      <td>486</td>\n",
       "      <td>417</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583229</th>\n",
       "      <td>486</td>\n",
       "      <td>417</td>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>256</td>\n",
       "      <td>198</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>486</td>\n",
       "      <td>417</td>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1422.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583230</th>\n",
       "      <td>417</td>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>198</td>\n",
       "      <td>182</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.002175</td>\n",
       "      <td>417</td>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1382.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583231</th>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>182</td>\n",
       "      <td>170</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>339</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1307.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583232</th>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>170</td>\n",
       "      <td>196</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>313</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>1344.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583233</th>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>1316</td>\n",
       "      <td>196</td>\n",
       "      <td>183</td>\n",
       "      <td>705</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>356</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>1316</td>\n",
       "      <td>1467.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583234</th>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>1316</td>\n",
       "      <td>1373</td>\n",
       "      <td>183</td>\n",
       "      <td>705</td>\n",
       "      <td>711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>379</td>\n",
       "      <td>1409</td>\n",
       "      <td>1379</td>\n",
       "      <td>1466</td>\n",
       "      <td>1299</td>\n",
       "      <td>1316</td>\n",
       "      <td>1373</td>\n",
       "      <td>1431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583235</th>\n",
       "      <td>1300</td>\n",
       "      <td>1526</td>\n",
       "      <td>1311</td>\n",
       "      <td>1183</td>\n",
       "      <td>1445</td>\n",
       "      <td>1454</td>\n",
       "      <td>2047</td>\n",
       "      <td>639</td>\n",
       "      <td>658</td>\n",
       "      <td>544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1300</td>\n",
       "      <td>1526</td>\n",
       "      <td>1311</td>\n",
       "      <td>1183</td>\n",
       "      <td>1445</td>\n",
       "      <td>1454</td>\n",
       "      <td>2047</td>\n",
       "      <td>1380.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583236</th>\n",
       "      <td>1526</td>\n",
       "      <td>1311</td>\n",
       "      <td>1183</td>\n",
       "      <td>1445</td>\n",
       "      <td>1454</td>\n",
       "      <td>2047</td>\n",
       "      <td>1437</td>\n",
       "      <td>658</td>\n",
       "      <td>544</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1526</td>\n",
       "      <td>1311</td>\n",
       "      <td>1183</td>\n",
       "      <td>1445</td>\n",
       "      <td>1454</td>\n",
       "      <td>2047</td>\n",
       "      <td>1437</td>\n",
       "      <td>1300.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583237</th>\n",
       "      <td>1700</td>\n",
       "      <td>1386</td>\n",
       "      <td>1364</td>\n",
       "      <td>1437</td>\n",
       "      <td>1627</td>\n",
       "      <td>2040</td>\n",
       "      <td>1736</td>\n",
       "      <td>697</td>\n",
       "      <td>579</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1700</td>\n",
       "      <td>1386</td>\n",
       "      <td>1364</td>\n",
       "      <td>1437</td>\n",
       "      <td>1627</td>\n",
       "      <td>2040</td>\n",
       "      <td>1736</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583238</th>\n",
       "      <td>1280</td>\n",
       "      <td>1725</td>\n",
       "      <td>758</td>\n",
       "      <td>66</td>\n",
       "      <td>1254</td>\n",
       "      <td>1146</td>\n",
       "      <td>1353</td>\n",
       "      <td>493</td>\n",
       "      <td>527</td>\n",
       "      <td>293</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211255</td>\n",
       "      <td>1.197940</td>\n",
       "      <td>1287</td>\n",
       "      <td>1735</td>\n",
       "      <td>759</td>\n",
       "      <td>67</td>\n",
       "      <td>1257</td>\n",
       "      <td>1155</td>\n",
       "      <td>1359</td>\n",
       "      <td>1276.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583239</th>\n",
       "      <td>1725</td>\n",
       "      <td>758</td>\n",
       "      <td>66</td>\n",
       "      <td>1254</td>\n",
       "      <td>1146</td>\n",
       "      <td>1353</td>\n",
       "      <td>1298</td>\n",
       "      <td>527</td>\n",
       "      <td>293</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197940</td>\n",
       "      <td>1.249045</td>\n",
       "      <td>1735</td>\n",
       "      <td>759</td>\n",
       "      <td>67</td>\n",
       "      <td>1257</td>\n",
       "      <td>1155</td>\n",
       "      <td>1359</td>\n",
       "      <td>1309</td>\n",
       "      <td>1311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583240</th>\n",
       "      <td>758</td>\n",
       "      <td>66</td>\n",
       "      <td>1254</td>\n",
       "      <td>1146</td>\n",
       "      <td>1353</td>\n",
       "      <td>1298</td>\n",
       "      <td>1240</td>\n",
       "      <td>293</td>\n",
       "      <td>19</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249045</td>\n",
       "      <td>1.136656</td>\n",
       "      <td>759</td>\n",
       "      <td>67</td>\n",
       "      <td>1257</td>\n",
       "      <td>1155</td>\n",
       "      <td>1359</td>\n",
       "      <td>1309</td>\n",
       "      <td>1244</td>\n",
       "      <td>1299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583241</th>\n",
       "      <td>66</td>\n",
       "      <td>1254</td>\n",
       "      <td>1146</td>\n",
       "      <td>1353</td>\n",
       "      <td>1298</td>\n",
       "      <td>1240</td>\n",
       "      <td>1364</td>\n",
       "      <td>19</td>\n",
       "      <td>487</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136656</td>\n",
       "      <td>1.161829</td>\n",
       "      <td>67</td>\n",
       "      <td>1257</td>\n",
       "      <td>1155</td>\n",
       "      <td>1359</td>\n",
       "      <td>1309</td>\n",
       "      <td>1244</td>\n",
       "      <td>1378</td>\n",
       "      <td>1215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583242</th>\n",
       "      <td>1473</td>\n",
       "      <td>1518</td>\n",
       "      <td>1289</td>\n",
       "      <td>1228</td>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>527</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147557</td>\n",
       "      <td>1.155259</td>\n",
       "      <td>1483</td>\n",
       "      <td>1527</td>\n",
       "      <td>1300</td>\n",
       "      <td>1240</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583243</th>\n",
       "      <td>1518</td>\n",
       "      <td>1289</td>\n",
       "      <td>1228</td>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>1643</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155259</td>\n",
       "      <td>1.143549</td>\n",
       "      <td>1527</td>\n",
       "      <td>1300</td>\n",
       "      <td>1240</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1651</td>\n",
       "      <td>2107.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583244</th>\n",
       "      <td>1289</td>\n",
       "      <td>1228</td>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>1643</td>\n",
       "      <td>1626</td>\n",
       "      <td>582</td>\n",
       "      <td>487</td>\n",
       "      <td>506</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143549</td>\n",
       "      <td>1.185776</td>\n",
       "      <td>1300</td>\n",
       "      <td>1240</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1651</td>\n",
       "      <td>1631</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583245</th>\n",
       "      <td>1228</td>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>1643</td>\n",
       "      <td>1626</td>\n",
       "      <td>2582</td>\n",
       "      <td>487</td>\n",
       "      <td>506</td>\n",
       "      <td>752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185776</td>\n",
       "      <td>1.217879</td>\n",
       "      <td>1240</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1651</td>\n",
       "      <td>1631</td>\n",
       "      <td>2584</td>\n",
       "      <td>1490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583246</th>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>1643</td>\n",
       "      <td>1626</td>\n",
       "      <td>2582</td>\n",
       "      <td>1649</td>\n",
       "      <td>506</td>\n",
       "      <td>752</td>\n",
       "      <td>663</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217879</td>\n",
       "      <td>1.230072</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1651</td>\n",
       "      <td>1631</td>\n",
       "      <td>2584</td>\n",
       "      <td>1656</td>\n",
       "      <td>1407.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583247</th>\n",
       "      <td>1689</td>\n",
       "      <td>1468</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>1699</td>\n",
       "      <td>1565</td>\n",
       "      <td>1688</td>\n",
       "      <td>618</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129936</td>\n",
       "      <td>1.100945</td>\n",
       "      <td>1702</td>\n",
       "      <td>1478</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>1702</td>\n",
       "      <td>1570</td>\n",
       "      <td>1694</td>\n",
       "      <td>1465.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583248</th>\n",
       "      <td>1468</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>1699</td>\n",
       "      <td>1565</td>\n",
       "      <td>1688</td>\n",
       "      <td>1453</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>681</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100945</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1478</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>1702</td>\n",
       "      <td>1570</td>\n",
       "      <td>1694</td>\n",
       "      <td>1458</td>\n",
       "      <td>1606.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583249 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     2   0.1   0.2     1   1.1   1.2  0.3  1.3  0.4   ...    \\\n",
       "0          2     1     0     0     0     0     4    2    1    0   ...     \n",
       "1          1     0     0     0     0     4     1    1    0    0   ...     \n",
       "2          1     0     0     1     0     0     1    1    0    0   ...     \n",
       "3          0     1     0     0     1     2     3    0    1    0   ...     \n",
       "4          1     0     0     1     2     3     0    1    0    0   ...     \n",
       "5          1     0     0     0     2     0     2    1    0    0   ...     \n",
       "6          0     2     0     0     0     1     1    0    2    0   ...     \n",
       "7          2     0     0     0     1     1     2    2    0    0   ...     \n",
       "8          0     1     1     2     2     0     3    0    1    1   ...     \n",
       "9          1     1     2     2     0     3     1    1    1    2   ...     \n",
       "10         0     1     1     1     2     2     0    0    1    1   ...     \n",
       "11         0     1     1     0     0     0    12    0    1    1   ...     \n",
       "12         1     1     0     0     0    12    34    1    1    0   ...     \n",
       "13         1     0     0     0    12    34     1    1    0    0   ...     \n",
       "14         1     0    13     4    11     9    10    0    0    1   ...     \n",
       "15         0    13     4    11     9    10    18    0    1    2   ...     \n",
       "16        13     4    11     9    10    18    39    1    2    1   ...     \n",
       "17         4    11     9    10    18    39     8    2    1    5   ...     \n",
       "18        11     9    10    18    39     8    16    1    5    7   ...     \n",
       "19         9    10    18    39     8    16     0    5    7    4   ...     \n",
       "20         1     0     1     6     0     0     2    1    0    1   ...     \n",
       "21         0     1     6     0     0     2     2    0    1    3   ...     \n",
       "22         0     2     2     0     0     8     4    0    2    2   ...     \n",
       "23         2     2     0     0     8     4     1    2    2    0   ...     \n",
       "24         2     0     0     8     4     1     1    2    0    0   ...     \n",
       "25         1     0     0     0     0     8     0    1    0    0   ...     \n",
       "26         0     0     0     0     8     0     0    0    0    0   ...     \n",
       "27         0     0     0     8     0     0     3    0    0    1   ...     \n",
       "28         0     0     8     0     0     3     7    0    1    8   ...     \n",
       "29         0     8     0     0     3     7     2    1    8    0   ...     \n",
       "...      ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   ...     \n",
       "583219     8     8    27    17    11     9    12    4    6   11   ...     \n",
       "583220    27    17    11     9    12    17    21   11    5    6   ...     \n",
       "583221    17    11     9    12    17    21    14    5    6    5   ...     \n",
       "583222    11     9    12    17    21    14    22    6    5    7   ...     \n",
       "583223     9    12    17    21    14    22    13    5    7   10   ...     \n",
       "583224   435   349   386   317   325   441   511  231  173  182   ...     \n",
       "583225   349   386   317   325   441   511   417  173  182  173   ...     \n",
       "583226   317   325   441   511   417   419   747  173  117  217   ...     \n",
       "583227   325   441   511   417   419   747   363  117  217  261   ...     \n",
       "583228   363   329   414   514   533   486   417  168  167  196   ...     \n",
       "583229   486   417   339   313   356   379  1409  256  198  182   ...     \n",
       "583230   417   339   313   356   379  1409  1379  198  182  170   ...     \n",
       "583231   339   313   356   379  1409  1379  1466  182  170  196   ...     \n",
       "583232   313   356   379  1409  1379  1466  1299  170  196  183   ...     \n",
       "583233   356   379  1409  1379  1466  1299  1316  196  183  705   ...     \n",
       "583234   379  1409  1379  1466  1299  1316  1373  183  705  711   ...     \n",
       "583235  1300  1526  1311  1183  1445  1454  2047  639  658  544   ...     \n",
       "583236  1526  1311  1183  1445  1454  2047  1437  658  544  549   ...     \n",
       "583237  1700  1386  1364  1437  1627  2040  1736  697  579  501   ...     \n",
       "583238  1280  1725   758    66  1254  1146  1353  493  527  293   ...     \n",
       "583239  1725   758    66  1254  1146  1353  1298  527  293   19   ...     \n",
       "583240   758    66  1254  1146  1353  1298  1240  293   19  487   ...     \n",
       "583241    66  1254  1146  1353  1298  1240  1364   19  487  401   ...     \n",
       "583242  1473  1518  1289  1228  1343  1999  1789  527  582  582   ...     \n",
       "583243  1518  1289  1228  1343  1999  1789  1643  582  582  487   ...     \n",
       "583244  1289  1228  1343  1999  1789  1643  1626  582  487  506   ...     \n",
       "583245  1228  1343  1999  1789  1643  1626  2582  487  506  752   ...     \n",
       "583246  1343  1999  1789  1643  1626  2582  1649  506  752  663   ...     \n",
       "583247  1689  1468     0  1721  1699  1565  1688  618  610    0   ...     \n",
       "583248  1468     0  1721  1699  1565  1688  1453  610    0  681   ...     \n",
       "\n",
       "        1.000000.14  1.000000.15  0.12   2.2  0.13  0.14  1.14  1.15  1.16  \\\n",
       "0          0.000000     1.000000     2     1     0     0     0     0     4   \n",
       "1          1.000000     1.000000     1     0     0     0     0     4     1   \n",
       "2          0.000000     1.000000     1     0     0     1     0     0     1   \n",
       "3          1.000000     1.000000     0     1     0     0     1     2     3   \n",
       "4          1.000000     0.000000     1     0     0     1     2     3     0   \n",
       "5          0.000000     1.000000     1     0     0     0     2     0     2   \n",
       "6          1.000000     1.000000     0     2     0     0     0     1     1   \n",
       "7          1.000000     1.000000     2     0     0     0     1     1     2   \n",
       "8          0.000000     1.000000     0     1     1     2     2     0     3   \n",
       "9          1.000000     1.000000     1     1     2     2     0     3     1   \n",
       "10         1.000000     0.000000     0     1     1     1     2     2     0   \n",
       "11         0.000000     1.000000     0     1     1     0     0     0    12   \n",
       "12         1.000000     1.000000     1     1     0     0     0    12    34   \n",
       "13         1.000000     1.000000     1     0     0     0    12    34     1   \n",
       "14         1.000000     1.000000     1     0    13     4    11     9    10   \n",
       "15         1.000000     1.000000     0    13     4    11     9    10    18   \n",
       "16         1.000000     1.000000    13     4    11     9    10    18    39   \n",
       "17         1.000000     1.000000     4    11     9    10    18    39     8   \n",
       "18         1.000000     1.000000    11     9    10    18    39     8    16   \n",
       "19         1.000000     0.000000     9    10    18    39     8    16     0   \n",
       "20         0.000000     1.000000     1     0     1     6     0     0     2   \n",
       "21         1.000000     1.000000     0     1     6     0     0     2     2   \n",
       "22         2.125000     4.750000     0     2     2     0     0     8     4   \n",
       "23         4.750000     3.000000     2     2     0     0     8     4     1   \n",
       "24         3.000000     3.000000     2     0     0     8     4     1     2   \n",
       "25         1.000000     0.000000     2     1     1     0     1     8     0   \n",
       "26         0.000000     0.000000     1     1     0     1     8     0     0   \n",
       "27         0.000000     1.666667     1     0     1     8     0     0     3   \n",
       "28         1.666667     2.428571     0     1     8     0     0     3     7   \n",
       "29         2.428571     1.500000     1     8     0     0     3     7     2   \n",
       "...             ...          ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "583219     1.555556     1.384615     8     8    27    17    11     9    13   \n",
       "583220     1.277778     1.380952    27    17    11     9    13    18    21   \n",
       "583221     1.380952     1.000000    17    11     9    13    18    21    14   \n",
       "583222     1.000000     1.090909    11     9    13    18    21    14    22   \n",
       "583223     1.090909     1.538462     9    13    18    21    14    22    13   \n",
       "583224     1.000000     1.000000   435   349   386   317   325   441   511   \n",
       "583225     1.000000     1.000000   349   386   317   325   441   511   417   \n",
       "583226     1.000000     1.000000   317   325   441   511   417   419   747   \n",
       "583227     1.000000     1.000000   325   441   511   417   419   747   363   \n",
       "583228     1.000000     1.000000   363   329   414   514   533   486   417   \n",
       "583229     1.000000     1.000000   486   417   339   313   356   379  1409   \n",
       "583230     1.000000     1.002175   417   339   313   356   379  1409  1379   \n",
       "583231     1.002175     1.000000   339   313   356   379  1409  1379  1466   \n",
       "583232     1.000000     1.000000   313   356   379  1409  1379  1466  1299   \n",
       "583233     1.000000     1.000000   356   379  1409  1379  1466  1299  1316   \n",
       "583234     1.000000     1.000000   379  1409  1379  1466  1299  1316  1373   \n",
       "583235     1.000000     1.000000  1300  1526  1311  1183  1445  1454  2047   \n",
       "583236     1.000000     1.000000  1526  1311  1183  1445  1454  2047  1437   \n",
       "583237     1.000490     1.000000  1700  1386  1364  1437  1627  2040  1736   \n",
       "583238     1.211255     1.197940  1287  1735   759    67  1257  1155  1359   \n",
       "583239     1.197940     1.249045  1735   759    67  1257  1155  1359  1309   \n",
       "583240     1.249045     1.136656   759    67  1257  1155  1359  1309  1244   \n",
       "583241     1.136656     1.161829    67  1257  1155  1359  1309  1244  1378   \n",
       "583242     1.147557     1.155259  1483  1527  1300  1240  1352  2006  1797   \n",
       "583243     1.155259     1.143549  1527  1300  1240  1352  2006  1797  1651   \n",
       "583244     1.143549     1.185776  1300  1240  1352  2006  1797  1651  1631   \n",
       "583245     1.185776     1.217879  1240  1352  2006  1797  1651  1631  2584   \n",
       "583246     1.217879     1.230072  1352  2006  1797  1651  1631  2584  1656   \n",
       "583247     1.129936     1.100945  1702  1478     0  1722  1702  1570  1694   \n",
       "583248     1.100945     1.185185  1478     0  1722  1702  1570  1694  1458   \n",
       "\n",
       "           0.0  \n",
       "0          0.5  \n",
       "1          0.0  \n",
       "2          2.5  \n",
       "3          0.5  \n",
       "4          1.0  \n",
       "5          0.0  \n",
       "6          2.0  \n",
       "7          1.0  \n",
       "8          0.5  \n",
       "9          0.5  \n",
       "10         0.0  \n",
       "11        17.5  \n",
       "12         0.5  \n",
       "13         6.5  \n",
       "14        28.5  \n",
       "15        23.5  \n",
       "16        12.0  \n",
       "17         8.0  \n",
       "18         1.0  \n",
       "19         6.0  \n",
       "20         1.0  \n",
       "21         0.0  \n",
       "22         1.5  \n",
       "23         2.0  \n",
       "24         1.5  \n",
       "25         1.5  \n",
       "26         5.0  \n",
       "27         4.5  \n",
       "28         4.0  \n",
       "29         3.0  \n",
       "...        ...  \n",
       "583219    19.5  \n",
       "583220    18.0  \n",
       "583221    17.5  \n",
       "583222    12.0  \n",
       "583223    11.0  \n",
       "583224   418.0  \n",
       "583225   583.0  \n",
       "583226   346.0  \n",
       "583227   371.5  \n",
       "583228   326.0  \n",
       "583229  1422.5  \n",
       "583230  1382.5  \n",
       "583231  1307.5  \n",
       "583232  1344.5  \n",
       "583233  1467.5  \n",
       "583234  1431.0  \n",
       "583235  1380.5  \n",
       "583236  1300.5  \n",
       "583237  1625.0  \n",
       "583238  1276.5  \n",
       "583239  1311.0  \n",
       "583240  1299.0  \n",
       "583241  1215.0  \n",
       "583242  1641.0  \n",
       "583243  2107.5  \n",
       "583244  2120.0  \n",
       "583245  1490.0  \n",
       "583246  1407.5  \n",
       "583247  1465.5  \n",
       "583248  1606.0  \n",
       "\n",
       "[583249 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table('Twitter.data', sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCD_0</th>\n",
       "      <th>NCD_1</th>\n",
       "      <th>NCD_2</th>\n",
       "      <th>NCD_3</th>\n",
       "      <th>NCD_4</th>\n",
       "      <th>NCD_5</th>\n",
       "      <th>NCD_6</th>\n",
       "      <th>AI_0</th>\n",
       "      <th>AI_1</th>\n",
       "      <th>AI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>ADL_5</th>\n",
       "      <th>ADL_6</th>\n",
       "      <th>NAD_0</th>\n",
       "      <th>NAD_1</th>\n",
       "      <th>NAD_2</th>\n",
       "      <th>NAD_3</th>\n",
       "      <th>NAD_4</th>\n",
       "      <th>NAD_5</th>\n",
       "      <th>NAD_6</th>\n",
       "      <th>NAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "      <td>583249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>140.339881</td>\n",
       "      <td>136.770378</td>\n",
       "      <td>159.679545</td>\n",
       "      <td>181.592402</td>\n",
       "      <td>201.097788</td>\n",
       "      <td>220.175747</td>\n",
       "      <td>219.388589</td>\n",
       "      <td>71.038172</td>\n",
       "      <td>69.829749</td>\n",
       "      <td>82.198344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136689</td>\n",
       "      <td>1.140372</td>\n",
       "      <td>140.790102</td>\n",
       "      <td>137.181502</td>\n",
       "      <td>160.106196</td>\n",
       "      <td>182.057752</td>\n",
       "      <td>201.596826</td>\n",
       "      <td>220.706276</td>\n",
       "      <td>219.937239</td>\n",
       "      <td>191.279821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>431.772970</td>\n",
       "      <td>432.305464</td>\n",
       "      <td>502.057815</td>\n",
       "      <td>574.884157</td>\n",
       "      <td>630.448918</td>\n",
       "      <td>669.206442</td>\n",
       "      <td>672.182719</td>\n",
       "      <td>196.876865</td>\n",
       "      <td>202.199911</td>\n",
       "      <td>239.523223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432328</td>\n",
       "      <td>1.552315</td>\n",
       "      <td>432.625285</td>\n",
       "      <td>433.026946</td>\n",
       "      <td>502.774795</td>\n",
       "      <td>575.658466</td>\n",
       "      <td>631.258804</td>\n",
       "      <td>670.051490</td>\n",
       "      <td>673.033057</td>\n",
       "      <td>612.352828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.091298</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24210.000000</td>\n",
       "      <td>29574.000000</td>\n",
       "      <td>37505.000000</td>\n",
       "      <td>72366.000000</td>\n",
       "      <td>79079.000000</td>\n",
       "      <td>79079.000000</td>\n",
       "      <td>79079.000000</td>\n",
       "      <td>18654.000000</td>\n",
       "      <td>22035.000000</td>\n",
       "      <td>29402.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>24301.000000</td>\n",
       "      <td>29574.000000</td>\n",
       "      <td>37505.000000</td>\n",
       "      <td>72366.000000</td>\n",
       "      <td>79083.000000</td>\n",
       "      <td>79083.000000</td>\n",
       "      <td>79083.000000</td>\n",
       "      <td>75724.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               NCD_0          NCD_1          NCD_2          NCD_3  \\\n",
       "count  583249.000000  583249.000000  583249.000000  583249.000000   \n",
       "mean      140.339881     136.770378     159.679545     181.592402   \n",
       "std       431.772970     432.305464     502.057815     574.884157   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%        18.000000      17.000000      21.000000      24.000000   \n",
       "75%       104.000000     100.000000     115.000000     131.000000   \n",
       "max     24210.000000   29574.000000   37505.000000   72366.000000   \n",
       "\n",
       "               NCD_4          NCD_5          NCD_6           AI_0  \\\n",
       "count  583249.000000  583249.000000  583249.000000  583249.000000   \n",
       "mean      201.097788     220.175747     219.388589      71.038172   \n",
       "std       630.448918     669.206442     672.182719     196.876865   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         5.000000       6.000000       6.000000       2.000000   \n",
       "50%        27.000000      31.000000      30.000000      11.000000   \n",
       "75%       147.000000     166.000000     164.000000      59.000000   \n",
       "max     79079.000000   79079.000000   79079.000000   18654.000000   \n",
       "\n",
       "                AI_1           AI_2      ...                ADL_5  \\\n",
       "count  583249.000000  583249.000000      ...        583249.000000   \n",
       "mean       69.829749      82.198344      ...             1.136689   \n",
       "std       202.199911     239.523223      ...             1.432328   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         2.000000       2.000000      ...             1.000000   \n",
       "50%        11.000000      13.000000      ...             1.000000   \n",
       "75%        57.000000      65.000000      ...             1.090909   \n",
       "max     22035.000000   29402.000000      ...           262.000000   \n",
       "\n",
       "               ADL_6          NAD_0          NAD_1          NAD_2  \\\n",
       "count  583249.000000  583249.000000  583249.000000  583249.000000   \n",
       "mean        1.140372     140.790102     137.181502     160.106196   \n",
       "std         1.552315     432.625285     433.026946     502.774795   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       3.000000       3.000000       4.000000   \n",
       "50%         1.000000      18.000000      17.000000      21.000000   \n",
       "75%         1.091298     104.000000     101.000000     115.000000   \n",
       "max       295.000000   24301.000000   29574.000000   37505.000000   \n",
       "\n",
       "               NAD_3          NAD_4          NAD_5          NAD_6  \\\n",
       "count  583249.000000  583249.000000  583249.000000  583249.000000   \n",
       "mean      182.057752     201.596826     220.706276     219.937239   \n",
       "std       575.658466     631.258804     670.051490     673.033057   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         4.000000       5.000000       6.000000       6.000000   \n",
       "50%        24.000000      27.000000      31.000000      31.000000   \n",
       "75%       131.000000     148.000000     167.000000     165.000000   \n",
       "max     72366.000000   79083.000000   79083.000000   79083.000000   \n",
       "\n",
       "                 NAD  \n",
       "count  583249.000000  \n",
       "mean      191.279821  \n",
       "std       612.352828  \n",
       "min         0.000000  \n",
       "25%         4.500000  \n",
       "50%        25.500000  \n",
       "75%       139.000000  \n",
       "max     75724.500000  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = columnnames\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583249 entries, 0 to 583248\n",
      "Data columns (total 78 columns):\n",
      "NCD_0        583249 non-null int64\n",
      "NCD_1        583249 non-null int64\n",
      "NCD_2        583249 non-null int64\n",
      "NCD_3        583249 non-null int64\n",
      "NCD_4        583249 non-null int64\n",
      "NCD_5        583249 non-null int64\n",
      "NCD_6        583249 non-null int64\n",
      "AI_0         583249 non-null int64\n",
      "AI_1         583249 non-null int64\n",
      "AI_2         583249 non-null int64\n",
      "AI_3         583249 non-null int64\n",
      "AI_4         583249 non-null int64\n",
      "AI_5         583249 non-null int64\n",
      "AI_6         583249 non-null int64\n",
      "AS(NA)_0     583249 non-null float64\n",
      "AS(NA)_1     583249 non-null float64\n",
      "AS(NA)_2     583249 non-null float64\n",
      "AS(NA)_3     583249 non-null float64\n",
      "AS(NA)_4     583249 non-null float64\n",
      "AS(NA)_5     583249 non-null float64\n",
      "AS(NA)_6     583249 non-null float64\n",
      "BL_0         583249 non-null float64\n",
      "BL_1         583249 non-null float64\n",
      "BL_2         583249 non-null float64\n",
      "BL_3         583249 non-null float64\n",
      "BL_4         583249 non-null float64\n",
      "BL_5         583249 non-null float64\n",
      "BL_6         583249 non-null float64\n",
      "NAC_0        583249 non-null int64\n",
      "NAC_1        583249 non-null int64\n",
      "NAC_2        583249 non-null int64\n",
      "NAC_3        583249 non-null int64\n",
      "NAC_4        583249 non-null int64\n",
      "NAC_5        583249 non-null int64\n",
      "NAC_6        583249 non-null int64\n",
      "AS(NAC)_0    583249 non-null float64\n",
      "AS(NAC)_1    583249 non-null float64\n",
      "AS(NAC)_2    583249 non-null float64\n",
      "AS(NAC)_3    583249 non-null float64\n",
      "AS(NAC)_4    583249 non-null float64\n",
      "AS(NAC)_5    583249 non-null float64\n",
      "AS(NAC)_6    583249 non-null float64\n",
      "CS_0         583249 non-null float64\n",
      "CS_1         583249 non-null float64\n",
      "CS_2         583249 non-null float64\n",
      "CS_3         583249 non-null float64\n",
      "CS_4         583249 non-null float64\n",
      "CS_5         583249 non-null float64\n",
      "CS_6         583249 non-null float64\n",
      "AT_0         583249 non-null float64\n",
      "AT_1         583249 non-null float64\n",
      "AT_2         583249 non-null float64\n",
      "AT_3         583249 non-null float64\n",
      "AT_4         583249 non-null float64\n",
      "AT_5         583249 non-null float64\n",
      "AT_6         583249 non-null float64\n",
      "NA_0         583249 non-null int64\n",
      "NA_1         583249 non-null int64\n",
      "NA_2         583249 non-null int64\n",
      "NA_3         583249 non-null int64\n",
      "NA_4         583249 non-null int64\n",
      "NA_5         583249 non-null int64\n",
      "NA_6         583249 non-null int64\n",
      "ADL_0        583249 non-null float64\n",
      "ADL_1        583249 non-null float64\n",
      "ADL_2        583249 non-null float64\n",
      "ADL_3        583249 non-null float64\n",
      "ADL_4        583249 non-null float64\n",
      "ADL_5        583249 non-null float64\n",
      "ADL_6        583249 non-null float64\n",
      "NAD_0        583249 non-null int64\n",
      "NAD_1        583249 non-null int64\n",
      "NAD_2        583249 non-null int64\n",
      "NAD_3        583249 non-null int64\n",
      "NAD_4        583249 non-null int64\n",
      "NAD_5        583249 non-null int64\n",
      "NAD_6        583249 non-null int64\n",
      "NAD          583249 non-null float64\n",
      "dtypes: float64(43), int64(35)\n",
      "memory usage: 347.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : ,0:77]\n",
    "y = data.iloc[ : ,77:78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Model Selection we execute on 10% of the data\n",
    "Dummytrain,sample_data,Dummytrain2,sample_target = train_test_split(X, y, shuffle = True, test_size = 0.1)\n",
    "\n",
    "X = sample_data\n",
    "y = sample_target\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We choose the MinMaxScaler to scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)\n",
    "\n",
    "X_full_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43743, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Models Using Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RidgeRegression(Bagging)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Project 2 we have seen that the optimum value of alpha for Ridge Regression is 0.1\n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "bag_reg = BaggingRegressor(ridge, n_estimators = 100, max_samples= 500, n_jobs = -1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg.fit(X_train, y_train)\n",
    "train_score = bag_reg.score(X_train, y_train)\n",
    "test_score = bag_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = 'From Proj2: alpha=0.1'\n",
    "report_table = [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Best Parameters  Train accuracy  Test accuracy\n",
       "Model                                                                         \n",
       "RidgeRegression(Bagging)  From Proj2: alpha=0.1        0.894924       0.900935"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LassoRegression(Bagging)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#From Project 2 we have found that alpha=0.01 is the best parameter for Lasso Regression\n",
    "lasso = Lasso(alpha=0.01)\n",
    "bag_reg_lasso = BaggingRegressor(lasso, n_estimators = 100, max_samples= 500, n_jobs = -1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg_lasso.fit(X_train, y_train)\n",
    "train_score = bag_reg_lasso.score(X_train, y_train)\n",
    "test_score = bag_reg_lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = 'From Proj2: alpha=0.01'\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Best Parameters  Train accuracy  \\\n",
       "Model                                                              \n",
       "RidgeRegression(Bagging)   From Proj2: alpha=0.1        0.894924   \n",
       "LassoRegression(Bagging)  From Proj2: alpha=0.01        0.921194   \n",
       "\n",
       "                          Test accuracy  \n",
       "Model                                    \n",
       "RidgeRegression(Bagging)       0.900935  \n",
       "LassoRegression(Bagging)       0.946404  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Models with Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR with Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LinearSVR(Pasting)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Proj2 we know thet C=1000 best parameter for LinearSVR\n",
    "#bootstrap = False means Pasting\n",
    "regressor = LinearSVR(C=1000)\n",
    "bag_reg_LinSVR = BaggingRegressor(regressor, n_estimators = 100, max_samples= 500, bootstrap=False, n_jobs = -1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg_LinSVR.fit(X_train, y_train)\n",
    "train_score = bag_reg_LinSVR.score(X_train, y_train)\n",
    "test_score = bag_reg_LinSVR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = 'From Proj2: C=1000'\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Best Parameters  Train accuracy  \\\n",
       "Model                                                              \n",
       "RidgeRegression(Bagging)   From Proj2: alpha=0.1        0.894924   \n",
       "LassoRegression(Bagging)  From Proj2: alpha=0.01        0.921194   \n",
       "LinearSVR(Pasting)            From Proj2: C=1000        0.922910   \n",
       "\n",
       "                          Test accuracy  \n",
       "Model                                    \n",
       "RidgeRegression(Bagging)       0.900935  \n",
       "LassoRegression(Bagging)       0.946404  \n",
       "LinearSVR(Pasting)             0.940000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel SVR with Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'KernelSVR(Pasting)'\n",
    "\n",
    "regressor = SVR(kernel='rbf', C=10, gamma=0.1)\n",
    "bag_reg_KSVR = BaggingRegressor(regressor, n_estimators = 100, max_samples= 500, bootstrap=False, n_jobs = -1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg_KSVR.fit(X_train, y_train)\n",
    "train_score = bag_reg_KSVR.score(X_train, y_train)\n",
    "test_score = bag_reg_KSVR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = 'From Proj2: C=10,gamma=0.1'\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=10,gamma=0.1</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Best Parameters  Train accuracy  \\\n",
       "Model                                                                  \n",
       "RidgeRegression(Bagging)       From Proj2: alpha=0.1        0.894924   \n",
       "LassoRegression(Bagging)      From Proj2: alpha=0.01        0.921194   \n",
       "LinearSVR(Pasting)                From Proj2: C=1000        0.922910   \n",
       "KernelSVR(Pasting)        From Proj2: C=10,gamma=0.1       -0.059582   \n",
       "\n",
       "                          Test accuracy  \n",
       "Model                                    \n",
       "RidgeRegression(Bagging)       0.900935  \n",
       "LassoRegression(Bagging)       0.946404  \n",
       "LinearSVR(Pasting)             0.940000  \n",
       "KernelSVR(Pasting)            -0.043834  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Models with Adaboost Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "model_name = 'DTree(Adaboost)'\n",
    "\n",
    "dtree = DecisionTreeRegressor()\n",
    "param_grid = {'base_estimator__max_depth': [3, 5, 7, 9, 12]}\n",
    "adatree = AdaBoostRegressor(dtree, n_estimators = 100, learning_rate= 0.5, random_state=0)\n",
    "\n",
    "#Since Decision Tree Regressor was not a part of Project 2 - Hence we need to find out the optimum tree depth\n",
    "grid = GridSearchCV(adatree, param_grid, cv=5, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "train_score = grid.score(X_train, y_train)\n",
    "test_score = grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'base_estimator__max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = str(grid.best_params_)\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=10,gamma=0.1</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree(Adaboost)</th>\n",
       "      <td>{'base_estimator__max_depth': 12}</td>\n",
       "      <td>0.992776</td>\n",
       "      <td>0.879385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Best Parameters  Train accuracy  \\\n",
       "Model                                                                         \n",
       "RidgeRegression(Bagging)              From Proj2: alpha=0.1        0.894924   \n",
       "LassoRegression(Bagging)             From Proj2: alpha=0.01        0.921194   \n",
       "LinearSVR(Pasting)                       From Proj2: C=1000        0.922910   \n",
       "KernelSVR(Pasting)               From Proj2: C=10,gamma=0.1       -0.059582   \n",
       "DTree(Adaboost)           {'base_estimator__max_depth': 12}        0.992776   \n",
       "\n",
       "                          Test accuracy  \n",
       "Model                                    \n",
       "RidgeRegression(Bagging)       0.900935  \n",
       "LassoRegression(Bagging)       0.946404  \n",
       "LinearSVR(Pasting)             0.940000  \n",
       "KernelSVR(Pasting)            -0.043834  \n",
       "DTree(Adaboost)                0.879385  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regressor with Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model_name = 'LinearRegression(Adaboost)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LinearRegression()\n",
    "adatree = AdaBoostRegressor(lreg, n_estimators = 100, learning_rate= 0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatree.fit(X_train, y_train)\n",
    "train_score = adatree.score(X_train, y_train)\n",
    "test_score = adatree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = 'N/A'\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=10,gamma=0.1</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree(Adaboost)</th>\n",
       "      <td>{'base_estimator__max_depth': 12}</td>\n",
       "      <td>0.992776</td>\n",
       "      <td>0.879385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression(Adaboost)</th>\n",
       "      <td>From Proj2: n_neighbors=3</td>\n",
       "      <td>0.722812</td>\n",
       "      <td>0.756270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression(Adaboost)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.722812</td>\n",
       "      <td>0.756270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Best Parameters  Train accuracy  \\\n",
       "Model                                                                           \n",
       "RidgeRegression(Bagging)                From Proj2: alpha=0.1        0.894924   \n",
       "LassoRegression(Bagging)               From Proj2: alpha=0.01        0.921194   \n",
       "LinearSVR(Pasting)                         From Proj2: C=1000        0.922910   \n",
       "KernelSVR(Pasting)                 From Proj2: C=10,gamma=0.1       -0.059582   \n",
       "DTree(Adaboost)             {'base_estimator__max_depth': 12}        0.992776   \n",
       "LinearRegression(Adaboost)          From Proj2: n_neighbors=3        0.722812   \n",
       "LinearRegression(Adaboost)                                N/A        0.722812   \n",
       "\n",
       "                            Test accuracy  \n",
       "Model                                      \n",
       "RidgeRegression(Bagging)         0.900935  \n",
       "LassoRegression(Bagging)         0.946404  \n",
       "LinearSVR(Pasting)               0.940000  \n",
       "KernelSVR(Pasting)              -0.043834  \n",
       "DTree(Adaboost)                  0.879385  \n",
       "LinearRegression(Adaboost)       0.756270  \n",
       "LinearRegression(Adaboost)       0.756270  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Model with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name ='GradientBoostingRegressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a trade-off between learning rate and number of estimators, hence we will do a grid search\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=3, random_state=0)\n",
    "param_grid = {'n_estimators': [100, 200], 'learning_rate':[0.5, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbrt = GridSearchCV(gbrt, param_grid, cv=5, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbrt.fit(X_train, y_train)\n",
    "train_score = grid_gbrt.score(X_train, y_train)\n",
    "test_score = grid_gbrt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = str(grid_gbrt.best_params_)\n",
    "print(\"Best parameters: {}\".format(grid_gbrt.best_params_))\n",
    "report_table = report_table + [[model_name, best_parameters, train_score, test_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(Bagging)</th>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(Pasting)</th>\n",
       "      <td>From Proj2: C=10,gamma=0.1</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree(Adaboost)</th>\n",
       "      <td>{'base_estimator__max_depth': 12}</td>\n",
       "      <td>0.992776</td>\n",
       "      <td>0.879385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression(Adaboost)</th>\n",
       "      <td>From Proj2: n_neighbors=3</td>\n",
       "      <td>0.722812</td>\n",
       "      <td>0.756270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression(Adaboost)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.722812</td>\n",
       "      <td>0.756270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.979853</td>\n",
       "      <td>0.865416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Best Parameters  \\\n",
       "Model                                                                     \n",
       "RidgeRegression(Bagging)                          From Proj2: alpha=0.1   \n",
       "LassoRegression(Bagging)                         From Proj2: alpha=0.01   \n",
       "LinearSVR(Pasting)                                   From Proj2: C=1000   \n",
       "KernelSVR(Pasting)                           From Proj2: C=10,gamma=0.1   \n",
       "DTree(Adaboost)                       {'base_estimator__max_depth': 12}   \n",
       "LinearRegression(Adaboost)                    From Proj2: n_neighbors=3   \n",
       "LinearRegression(Adaboost)                                          N/A   \n",
       "GradientBoostingRegressor   {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "                            Train accuracy  Test accuracy  \n",
       "Model                                                      \n",
       "RidgeRegression(Bagging)          0.894924       0.900935  \n",
       "LassoRegression(Bagging)          0.921194       0.946404  \n",
       "LinearSVR(Pasting)                0.922910       0.940000  \n",
       "KernelSVR(Pasting)               -0.059582      -0.043834  \n",
       "DTree(Adaboost)                   0.992776       0.879385  \n",
       "LinearRegression(Adaboost)        0.722812       0.756270  \n",
       "LinearRegression(Adaboost)        0.722812       0.756270  \n",
       "GradientBoostingRegressor         0.979853       0.865416  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appending the model specific report\n",
    "report_tabledf = pd.DataFrame(report_table, columns = ['Model', 'Best Parameters', 'Train accuracy', 'Test accuracy']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please ignore the duplicate entry here for Linear Regression - this has been corrected at the end in thr final report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Dataset through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "#First Scaling the Data\n",
    "X_scaled = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95) #We apply Principal Component Analysis to explain the maximum variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58325, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us see how many components our dataset got reduced to ?\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that 77 features have been reduced to 18 principal components that explain the maximum variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_train, X_reduced_test, y_train, y_test = train_test_split(X_reduced, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Regression - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LinearRegression(PCA)'\n",
    "train_score_proj2 = '0.943913773'\n",
    "test_score_proj2 = '0.965617145'\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_reduced_train, y_train)\n",
    "train_score = lreg.score(X_reduced_train, y_train)\n",
    "test_score= lreg.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'N/A'\n",
    "report_table_PCA_comp = [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RidgeRegression(PCA)'\n",
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X_reduced_train, y_train)\n",
    "train_score = ridge.score(X_reduced_train, y_train)\n",
    "test_score = ridge.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897009378531337\n"
     ]
    }
   ],
   "source": [
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "RidgeRegression(PCA)                      alpha=0.1        0.897009   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "RidgeRegression(PCA)        0.892767             0.943150861   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  \n",
       "RidgeRegression(PCA)             0.964527046  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'alpha=0.1'\n",
    "train_score_proj2 = '0.943150861'\n",
    "test_score_proj2 = '0.964527046'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso Regression - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_name = 'LassoRegression(PCA)'\n",
    "train_score_proj2 = '0.942930733'\n",
    "test_score_proj2 = '0.965217344'\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_reduced_train, y_train)\n",
    "train_score = lasso.score(X_reduced_train, y_train)\n",
    "test_score = lasso.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(PCA)</th>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942930733</td>\n",
       "      <td>0.965217344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "RidgeRegression(PCA)                      alpha=0.1        0.897009   \n",
       "LassoRegression(PCA)                     alpha=0.01        0.897009   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "RidgeRegression(PCA)        0.892767             0.943150861   \n",
       "LassoRegression(PCA)        0.892765             0.942930733   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  \n",
       "RidgeRegression(PCA)             0.964527046  \n",
       "LassoRegression(PCA)             0.965217344  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'alpha=0.01'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LinearSVR - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firstly working with Linear SVR\n",
    "model_name = 'LinearSVR(PCA)'\n",
    "train_score_proj2 = '0.933516144'\n",
    "test_score_proj2 = '0.957627962'\n",
    "\n",
    "#First doing linear SVR\n",
    "\n",
    "regressor = LinearSVR(C=1000)\n",
    "regressor.fit(X_reduced_train, y_train)\n",
    "train_score = regressor.score(X_reduced_train, y_train)\n",
    "test_score = regressor.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(PCA)</th>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942930733</td>\n",
       "      <td>0.965217344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(PCA)</th>\n",
       "      <td>C=1000</td>\n",
       "      <td>0.860143</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.933516144</td>\n",
       "      <td>0.957627962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "RidgeRegression(PCA)                      alpha=0.1        0.897009   \n",
       "LassoRegression(PCA)                     alpha=0.01        0.897009   \n",
       "LinearSVR(PCA)                               C=1000        0.860143   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "RidgeRegression(PCA)        0.892767             0.943150861   \n",
       "LassoRegression(PCA)        0.892765             0.942930733   \n",
       "LinearSVR(PCA)              0.851986             0.933516144   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  \n",
       "RidgeRegression(PCA)             0.964527046  \n",
       "LassoRegression(PCA)             0.965217344  \n",
       "LinearSVR(PCA)                   0.957627962  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'C=1000'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kernel SVR with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now working with Kernel SVC \n",
    "\n",
    "model_name = 'KernelSVR(PCA)'\n",
    "train_score_proj2 = '0.5868945'\n",
    "test_score_proj2 = '0.41803067'\n",
    "\n",
    "regressor = SVR(kernel='rbf', C=10, gamma=0.1)\n",
    "\n",
    "regressor.fit(X_reduced_train, y_train)\n",
    "train_score = regressor.score(X_reduced_train, y_train)\n",
    "test_score = regressor.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(PCA)</th>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942930733</td>\n",
       "      <td>0.965217344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(PCA)</th>\n",
       "      <td>C=1000</td>\n",
       "      <td>0.860143</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.933516144</td>\n",
       "      <td>0.957627962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(PCA)</th>\n",
       "      <td>C=10; gamma=0.1</td>\n",
       "      <td>0.195885</td>\n",
       "      <td>0.137391</td>\n",
       "      <td>0.5868945</td>\n",
       "      <td>0.41803067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "RidgeRegression(PCA)                      alpha=0.1        0.897009   \n",
       "LassoRegression(PCA)                     alpha=0.01        0.897009   \n",
       "LinearSVR(PCA)                               C=1000        0.860143   \n",
       "KernelSVR(PCA)                      C=10; gamma=0.1        0.195885   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "RidgeRegression(PCA)        0.892767             0.943150861   \n",
       "LassoRegression(PCA)        0.892765             0.942930733   \n",
       "LinearSVR(PCA)              0.851986             0.933516144   \n",
       "KernelSVR(PCA)              0.137391               0.5868945   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  \n",
       "RidgeRegression(PCA)             0.964527046  \n",
       "LassoRegression(PCA)             0.965217344  \n",
       "LinearSVR(PCA)                   0.957627962  \n",
       "KernelSVR(PCA)                    0.41803067  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'C=10; gamma=0.1'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'KNNRegression(PCA)'\n",
    "train_score_proj2 = '0.953085635'\n",
    "test_score_proj2 = '0.839912043'\n",
    "\n",
    "knnreg =  KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "knnreg.fit(X_reduced_train, y_train)\n",
    "train_score = knnreg.score(X_reduced_train, y_train)\n",
    "test_score = knnreg.score(X_reduced_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(PCA)</th>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942930733</td>\n",
       "      <td>0.965217344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(PCA)</th>\n",
       "      <td>C=1000</td>\n",
       "      <td>0.860143</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.933516144</td>\n",
       "      <td>0.957627962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(PCA)</th>\n",
       "      <td>C=10; gamma=0.1</td>\n",
       "      <td>0.195885</td>\n",
       "      <td>0.137391</td>\n",
       "      <td>0.5868945</td>\n",
       "      <td>0.41803067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNRegression(PCA)</th>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.947255</td>\n",
       "      <td>0.857080</td>\n",
       "      <td>0.953085635</td>\n",
       "      <td>0.839912043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                 \n",
       "LinearRegression(PCA)                           N/A        0.897009   \n",
       "RidgeRegression(PCA)                      alpha=0.1        0.897009   \n",
       "LassoRegression(PCA)                     alpha=0.01        0.897009   \n",
       "LinearSVR(PCA)                               C=1000        0.860143   \n",
       "KernelSVR(PCA)                      C=10; gamma=0.1        0.195885   \n",
       "KNNRegression(PCA)                    n_neighbors=3        0.947255   \n",
       "\n",
       "                       Test accuracy Train accuracy Project2  \\\n",
       "Model                                                          \n",
       "LinearRegression(PCA)       0.892767             0.943913773   \n",
       "RidgeRegression(PCA)        0.892767             0.943150861   \n",
       "LassoRegression(PCA)        0.892765             0.942930733   \n",
       "LinearSVR(PCA)              0.851986             0.933516144   \n",
       "KernelSVR(PCA)              0.137391               0.5868945   \n",
       "KNNRegression(PCA)          0.857080             0.953085635   \n",
       "\n",
       "                      Test accuracy Project2  \n",
       "Model                                         \n",
       "LinearRegression(PCA)            0.965617145  \n",
       "RidgeRegression(PCA)             0.964527046  \n",
       "LassoRegression(PCA)             0.965217344  \n",
       "LinearSVR(PCA)                   0.957627962  \n",
       "KernelSVR(PCA)                    0.41803067  \n",
       "KNNRegression(PCA)               0.839912043  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'n_neighbors=3'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polynomial Regression with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have already seen that polynomial features returns the best parameter as degree 1, so essentially it is a linear equestion.\n",
    "Hence we will try doing polynomial regreesion with degree 2 with PCA to see if results are any different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "model_name = 'PolynomialRegression(PCA)'\n",
    "train_score_proj2 = '0.943913773'\n",
    "test_score_proj2 = '0.965617145'\n",
    "#Defining the Polynomial Regression Function\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_reduced_train)\n",
    "X_test_poly = poly.transform(X_reduced_test)\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_poly, y_train)\n",
    "\n",
    "train_score = lreg.score(X_train_poly, y_train)\n",
    "test_score = lreg.score(X_test_poly, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(PCA)</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeRegression(PCA)</th>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943150861</td>\n",
       "      <td>0.964527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoRegression(PCA)</th>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942930733</td>\n",
       "      <td>0.965217344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR(PCA)</th>\n",
       "      <td>C=1000</td>\n",
       "      <td>0.860143</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.933516144</td>\n",
       "      <td>0.957627962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelSVR(PCA)</th>\n",
       "      <td>C=10; gamma=0.1</td>\n",
       "      <td>0.195885</td>\n",
       "      <td>0.137391</td>\n",
       "      <td>0.5868945</td>\n",
       "      <td>0.41803067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNRegression(PCA)</th>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.947255</td>\n",
       "      <td>0.857080</td>\n",
       "      <td>0.953085635</td>\n",
       "      <td>0.839912043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolynomialRegression(PCA)</th>\n",
       "      <td>Trial: Degree=2</td>\n",
       "      <td>0.932155</td>\n",
       "      <td>0.922674</td>\n",
       "      <td>0.943913773</td>\n",
       "      <td>0.965617145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Best Parameters from Project2  Train accuracy  \\\n",
       "Model                                                                     \n",
       "LinearRegression(PCA)                               N/A        0.897009   \n",
       "RidgeRegression(PCA)                          alpha=0.1        0.897009   \n",
       "LassoRegression(PCA)                         alpha=0.01        0.897009   \n",
       "LinearSVR(PCA)                                   C=1000        0.860143   \n",
       "KernelSVR(PCA)                          C=10; gamma=0.1        0.195885   \n",
       "KNNRegression(PCA)                        n_neighbors=3        0.947255   \n",
       "PolynomialRegression(PCA)               Trial: Degree=2        0.932155   \n",
       "\n",
       "                           Test accuracy Train accuracy Project2  \\\n",
       "Model                                                              \n",
       "LinearRegression(PCA)           0.892767             0.943913773   \n",
       "RidgeRegression(PCA)            0.892767             0.943150861   \n",
       "LassoRegression(PCA)            0.892765             0.942930733   \n",
       "LinearSVR(PCA)                  0.851986             0.933516144   \n",
       "KernelSVR(PCA)                  0.137391               0.5868945   \n",
       "KNNRegression(PCA)              0.857080             0.953085635   \n",
       "PolynomialRegression(PCA)       0.922674             0.943913773   \n",
       "\n",
       "                          Test accuracy Project2  \n",
       "Model                                             \n",
       "LinearRegression(PCA)                0.965617145  \n",
       "RidgeRegression(PCA)                 0.964527046  \n",
       "LassoRegression(PCA)                 0.965217344  \n",
       "LinearSVR(PCA)                       0.957627962  \n",
       "KernelSVR(PCA)                        0.41803067  \n",
       "KNNRegression(PCA)                   0.839912043  \n",
       "PolynomialRegression(PCA)            0.965617145  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = 'Trial: Degree=2'\n",
    "\n",
    "report_table_PCA_comp = report_table_PCA_comp + [[model_name, best_parameters, train_score, test_score, train_score_proj2, test_score_proj2]]\n",
    "\n",
    "report_tabledf = pd.DataFrame(report_table_PCA_comp, columns = ['Model', 'Best Parameters from Project2', 'Train accuracy', 'Test accuracy', 'Train accuracy Project2', 'Test accuracy Project2']).set_index('Model', drop=True)\n",
    "writer = ExcelWriter('RegressionReport_PCA_Project3.xlsx')\n",
    "report_tabledf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43743, 77)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, input_dim=77, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(11, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse', optimizer='sgd' , metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through Trial and Error we Try our different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = Sequential()\n",
    "bestmodel.add(Dense(45, input_dim=77, activation='relu'))\n",
    "bestmodel.add(Dense(25, activation='relu'))\n",
    "bestmodel.add(Dense(6, activation='relu'))\n",
    "bestmodel.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#compile model\n",
    "bestmodel.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0562 - mean_squared_error: 389079.0562\n",
      "Epoch 2/50\n",
      "43743/43743 [==============================] - 3s 61us/step - loss: 389079.0582 - mean_squared_error: 389079.0582\n",
      "Epoch 3/50\n",
      "43743/43743 [==============================] - 3s 61us/step - loss: 389079.0575 - mean_squared_error: 389079.0575\n",
      "Epoch 4/50\n",
      "43743/43743 [==============================] - 3s 65us/step - loss: 389079.0525 - mean_squared_error: 389079.0525\n",
      "Epoch 5/50\n",
      "43743/43743 [==============================] - 3s 62us/step - loss: 389079.0536 - mean_squared_error: 389079.0536\n",
      "Epoch 6/50\n",
      "43743/43743 [==============================] - 3s 62us/step - loss: 389079.0583 - mean_squared_error: 389079.0583\n",
      "Epoch 7/50\n",
      "43743/43743 [==============================] - 3s 62us/step - loss: 389079.0552 - mean_squared_error: 389079.0552\n",
      "Epoch 8/50\n",
      "43743/43743 [==============================] - 3s 63us/step - loss: 389079.0525 - mean_squared_error: 389079.0525\n",
      "Epoch 9/50\n",
      "43743/43743 [==============================] - 3s 63us/step - loss: 389079.0533 - mean_squared_error: 389079.0533\n",
      "Epoch 10/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0550 - mean_squared_error: 389079.0550\n",
      "Epoch 11/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0537 - mean_squared_error: 389079.0537\n",
      "Epoch 12/50\n",
      "43743/43743 [==============================] - 3s 69us/step - loss: 389079.0540 - mean_squared_error: 389079.0540\n",
      "Epoch 13/50\n",
      "43743/43743 [==============================] - 3s 67us/step - loss: 389079.0567 - mean_squared_error: 389079.0567\n",
      "Epoch 14/50\n",
      "43743/43743 [==============================] - 3s 69us/step - loss: 389079.0514 - mean_squared_error: 389079.0514\n",
      "Epoch 15/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0543 - mean_squared_error: 389079.0543\n",
      "Epoch 16/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0537 - mean_squared_error: 389079.0537\n",
      "Epoch 17/50\n",
      "43743/43743 [==============================] - 3s 64us/step - loss: 389079.0523 - mean_squared_error: 389079.0523\n",
      "Epoch 18/50\n",
      "43743/43743 [==============================] - 3s 65us/step - loss: 389079.0513 - mean_squared_error: 389079.0513\n",
      "Epoch 19/50\n",
      "43743/43743 [==============================] - 3s 68us/step - loss: 389079.0529 - mean_squared_error: 389079.0529\n",
      "Epoch 20/50\n",
      "43743/43743 [==============================] - 3s 66us/step - loss: 389079.0524 - mean_squared_error: 389079.0524\n",
      "Epoch 21/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0527 - mean_squared_error: 389079.0527\n",
      "Epoch 22/50\n",
      "43743/43743 [==============================] - 3s 67us/step - loss: 389079.0520 - mean_squared_error: 389079.0520\n",
      "Epoch 23/50\n",
      "43743/43743 [==============================] - 3s 67us/step - loss: 389079.0532 - mean_squared_error: 389079.0532\n",
      "Epoch 24/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0520 - mean_squared_error: 389079.0520\n",
      "Epoch 25/50\n",
      "43743/43743 [==============================] - 3s 73us/step - loss: 389079.0563 - mean_squared_error: 389079.0563\n",
      "Epoch 26/50\n",
      "43743/43743 [==============================] - 3s 73us/step - loss: 389079.0549 - mean_squared_error: 389079.0549\n",
      "Epoch 27/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0526 - mean_squared_error: 389079.0526\n",
      "Epoch 28/50\n",
      "43743/43743 [==============================] - 3s 73us/step - loss: 389079.0528 - mean_squared_error: 389079.0528\n",
      "Epoch 29/50\n",
      "43743/43743 [==============================] - 3s 74us/step - loss: 389079.0536 - mean_squared_error: 389079.0536\n",
      "Epoch 30/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0509 - mean_squared_error: 389079.0509\n",
      "Epoch 31/50\n",
      "43743/43743 [==============================] - 3s 75us/step - loss: 389079.0550 - mean_squared_error: 389079.0550\n",
      "Epoch 32/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0533 - mean_squared_error: 389079.0533\n",
      "Epoch 33/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0491 - mean_squared_error: 389079.0491\n",
      "Epoch 34/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0540 - mean_squared_error: 389079.0540\n",
      "Epoch 35/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0537 - mean_squared_error: 389079.0537\n",
      "Epoch 36/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0539 - mean_squared_error: 389079.0539\n",
      "Epoch 37/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0540 - mean_squared_error: 389079.0540\n",
      "Epoch 38/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0534 - mean_squared_error: 389079.0534\n",
      "Epoch 39/50\n",
      "43743/43743 [==============================] - 3s 72us/step - loss: 389079.0548 - mean_squared_error: 389079.0548\n",
      "Epoch 40/50\n",
      "43743/43743 [==============================] - 4s 90us/step - loss: 389079.0497 - mean_squared_error: 389079.0497\n",
      "Epoch 41/50\n",
      "43743/43743 [==============================] - 4s 89us/step - loss: 389079.0558 - mean_squared_error: 389079.0558\n",
      "Epoch 42/50\n",
      "43743/43743 [==============================] - 4s 84us/step - loss: 389079.0526 - mean_squared_error: 389079.0526\n",
      "Epoch 43/50\n",
      "43743/43743 [==============================] - 4s 82us/step - loss: 389079.0509 - mean_squared_error: 389079.0509\n",
      "Epoch 44/50\n",
      "43743/43743 [==============================] - 3s 70us/step - loss: 389079.0514 - mean_squared_error: 389079.0514\n",
      "Epoch 45/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0528 - mean_squared_error: 389079.0528\n",
      "Epoch 46/50\n",
      "43743/43743 [==============================] - 3s 74us/step - loss: 389079.0557 - mean_squared_error: 389079.0557\n",
      "Epoch 47/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0542 - mean_squared_error: 389079.0542\n",
      "Epoch 48/50\n",
      "43743/43743 [==============================] - 3s 71us/step - loss: 389079.0517 - mean_squared_error: 389079.0517\n",
      "Epoch 49/50\n",
      "43743/43743 [==============================] - 3s 73us/step - loss: 389079.0541 - mean_squared_error: 389079.0541\n",
      "Epoch 50/50\n",
      "43743/43743 [==============================] - 3s 73us/step - loss: 389079.0499 - mean_squared_error: 389079.0499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23bf0b9ec18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "bestmodel.fit(X_train, y_train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14582/14582 [==============================] - 0s 10us/step\n",
      "('mean_squared_error', 42360094.054634996)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = bestmodel.evaluate(X_test, y_test)\n",
    "print((bestmodel.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel2 = Sequential()\n",
    "bestmodel2.add(Dense(30, input_dim=77, activation='relu'))\n",
    "bestmodel2.add(Dense(20, activation='relu'))\n",
    "bestmodel2.add(Dense(15, activation='relu'))\n",
    "bestmodel2.add(Dense(11, activation='relu'))\n",
    "bestmodel2.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#compile model\n",
    "bestmodel2.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.1188 - mean_squared_error: 389079.1188\n",
      "Epoch 2/100\n",
      "43743/43743 [==============================] - 2s 35us/step - loss: 389079.0493 - mean_squared_error: 389079.0493\n",
      "Epoch 3/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0538 - mean_squared_error: 389079.0538\n",
      "Epoch 4/100\n",
      "43743/43743 [==============================] - 2s 35us/step - loss: 389079.0506 - mean_squared_error: 389079.0506\n",
      "Epoch 5/100\n",
      "43743/43743 [==============================] - 2s 35us/step - loss: 389079.0476 - mean_squared_error: 389079.0476\n",
      "Epoch 6/100\n",
      "43743/43743 [==============================] - 2s 35us/step - loss: 389079.0521 - mean_squared_error: 389079.0521\n",
      "Epoch 7/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0485 - mean_squared_error: 389079.0485\n",
      "Epoch 8/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0502 - mean_squared_error: 389079.0502\n",
      "Epoch 9/100\n",
      "43743/43743 [==============================] - 2s 35us/step - loss: 389079.0541 - mean_squared_error: 389079.0541\n",
      "Epoch 10/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0499 - mean_squared_error: 389079.0499\n",
      "Epoch 11/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0499 - mean_squared_error: 389079.0499\n",
      "Epoch 12/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0524 - mean_squared_error: 389079.0524\n",
      "Epoch 13/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 14/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0536 - mean_squared_error: 389079.0536\n",
      "Epoch 15/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0500 - mean_squared_error: 389079.0500\n",
      "Epoch 16/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0514 - mean_squared_error: 389079.0514\n",
      "Epoch 17/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0495 - mean_squared_error: 389079.0495\n",
      "Epoch 18/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0521 - mean_squared_error: 389079.0521\n",
      "Epoch 19/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0509 - mean_squared_error: 389079.0509\n",
      "Epoch 20/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0529 - mean_squared_error: 389079.0529\n",
      "Epoch 21/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0528 - mean_squared_error: 389079.0528\n",
      "Epoch 22/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0524 - mean_squared_error: 389079.0524\n",
      "Epoch 23/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0517 - mean_squared_error: 389079.0517\n",
      "Epoch 24/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0505 - mean_squared_error: 389079.0505\n",
      "Epoch 25/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 26/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0510 - mean_squared_error: 389079.0510\n",
      "Epoch 27/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0483 - mean_squared_error: 389079.0483\n",
      "Epoch 28/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0486 - mean_squared_error: 389079.0486\n",
      "Epoch 29/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 30/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0511 - mean_squared_error: 389079.0511\n",
      "Epoch 31/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 32/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 33/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0500 - mean_squared_error: 389079.0500\n",
      "Epoch 34/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0520 - mean_squared_error: 389079.0520\n",
      "Epoch 35/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0502 - mean_squared_error: 389079.0502\n",
      "Epoch 36/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0504 - mean_squared_error: 389079.0504\n",
      "Epoch 37/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0499 - mean_squared_error: 389079.0499\n",
      "Epoch 38/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0520 - mean_squared_error: 389079.0520\n",
      "Epoch 39/100\n",
      "43743/43743 [==============================] - 2s 53us/step - loss: 389079.0488 - mean_squared_error: 389079.0488\n",
      "Epoch 40/100\n",
      "43743/43743 [==============================] - 2s 50us/step - loss: 389079.0485 - mean_squared_error: 389079.0485\n",
      "Epoch 41/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0518 - mean_squared_error: 389079.0518\n",
      "Epoch 42/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0524 - mean_squared_error: 389079.0524\n",
      "Epoch 43/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0492 - mean_squared_error: 389079.0492\n",
      "Epoch 44/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0470 - mean_squared_error: 389079.0470\n",
      "Epoch 45/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0498 - mean_squared_error: 389079.0498\n",
      "Epoch 46/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0550 - mean_squared_error: 389079.0550\n",
      "Epoch 47/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0514 - mean_squared_error: 389079.0514\n",
      "Epoch 48/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0543 - mean_squared_error: 389079.0543\n",
      "Epoch 49/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0507 - mean_squared_error: 389079.0507\n",
      "Epoch 50/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 51/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0534 - mean_squared_error: 389079.0534\n",
      "Epoch 52/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0503 - mean_squared_error: 389079.0503\n",
      "Epoch 53/100\n",
      "43743/43743 [==============================] - 2s 49us/step - loss: 389079.0529 - mean_squared_error: 389079.0529\n",
      "Epoch 54/100\n",
      "43743/43743 [==============================] - 2s 44us/step - loss: 389079.0496 - mean_squared_error: 389079.0496\n",
      "Epoch 55/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0533 - mean_squared_error: 389079.0533\n",
      "Epoch 56/100\n",
      "43743/43743 [==============================] - 2s 41us/step - loss: 389079.0510 - mean_squared_error: 389079.0510\n",
      "Epoch 57/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 58/100\n",
      "43743/43743 [==============================] - 2s 48us/step - loss: 389079.0511 - mean_squared_error: 389079.0511\n",
      "Epoch 59/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0506 - mean_squared_error: 389079.0506\n",
      "Epoch 60/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 61/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0503 - mean_squared_error: 389079.0503\n",
      "Epoch 62/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0539 - mean_squared_error: 389079.0539\n",
      "Epoch 63/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0576 - mean_squared_error: 389079.0576\n",
      "Epoch 64/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0533 - mean_squared_error: 389079.0533\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0509 - mean_squared_error: 389079.0509\n",
      "Epoch 66/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0532 - mean_squared_error: 389079.0532\n",
      "Epoch 67/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0494 - mean_squared_error: 389079.0494\n",
      "Epoch 68/100\n",
      "43743/43743 [==============================] - ETA: 0s - loss: 390869.0315 - mean_squared_error: 390869.03 - 2s 35us/step - loss: 389079.0535 - mean_squared_error: 389079.0535\n",
      "Epoch 69/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0532 - mean_squared_error: 389079.0532\n",
      "Epoch 70/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0523 - mean_squared_error: 389079.0523\n",
      "Epoch 71/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0513 - mean_squared_error: 389079.0513\n",
      "Epoch 72/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0530 - mean_squared_error: 389079.0530\n",
      "Epoch 73/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0490 - mean_squared_error: 389079.0490\n",
      "Epoch 74/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 75/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0545 - mean_squared_error: 389079.0545\n",
      "Epoch 76/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0524 - mean_squared_error: 389079.0524\n",
      "Epoch 77/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0490 - mean_squared_error: 389079.0490\n",
      "Epoch 78/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0544 - mean_squared_error: 389079.0544\n",
      "Epoch 79/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0512 - mean_squared_error: 389079.0512\n",
      "Epoch 80/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0503 - mean_squared_error: 389079.0503\n",
      "Epoch 81/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0515 - mean_squared_error: 389079.0515\n",
      "Epoch 82/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0544 - mean_squared_error: 389079.0544\n",
      "Epoch 83/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 84/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0544 - mean_squared_error: 389079.0544\n",
      "Epoch 85/100\n",
      "43743/43743 [==============================] - 2s 36us/step - loss: 389079.0521 - mean_squared_error: 389079.0521\n",
      "Epoch 86/100\n",
      "43743/43743 [==============================] - 2s 37us/step - loss: 389079.0507 - mean_squared_error: 389079.0507\n",
      "Epoch 87/100\n",
      "43743/43743 [==============================] - 2s 39us/step - loss: 389079.0511 - mean_squared_error: 389079.0511\n",
      "Epoch 88/100\n",
      "43743/43743 [==============================] - 2s 38us/step - loss: 389079.0528 - mean_squared_error: 389079.0528\n",
      "Epoch 89/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0500 - mean_squared_error: 389079.0500\n",
      "Epoch 90/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0480 - mean_squared_error: 389079.0480\n",
      "Epoch 91/100\n",
      "43743/43743 [==============================] - 2s 41us/step - loss: 389079.0508 - mean_squared_error: 389079.0508\n",
      "Epoch 92/100\n",
      "43743/43743 [==============================] - 2s 41us/step - loss: 389079.0501 - mean_squared_error: 389079.0501\n",
      "Epoch 93/100\n",
      "43743/43743 [==============================] - 2s 43us/step - loss: 389079.0521 - mean_squared_error: 389079.0521\n",
      "Epoch 94/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0473 - mean_squared_error: 389079.0473\n",
      "Epoch 95/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0535 - mean_squared_error: 389079.0535\n",
      "Epoch 96/100\n",
      "43743/43743 [==============================] - 2s 40us/step - loss: 389079.0534 - mean_squared_error: 389079.0534\n",
      "Epoch 97/100\n",
      "43743/43743 [==============================] - 2s 43us/step - loss: 389079.0497 - mean_squared_error: 389079.0497\n",
      "Epoch 98/100\n",
      "43743/43743 [==============================] - 2s 43us/step - loss: 389079.0555 - mean_squared_error: 389079.0555\n",
      "Epoch 99/100\n",
      "43743/43743 [==============================] - 2s 43us/step - loss: 389079.0483 - mean_squared_error: 389079.0483\n",
      "Epoch 100/100\n",
      "43743/43743 [==============================] - 2s 42us/step - loss: 389079.0488 - mean_squared_error: 389079.0488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23bf0dfa198>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "bestmodel2.fit(X_train, y_train, epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Summary Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have two report tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble & Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RidgeRegression(Bagging)</td>\n",
       "      <td>From Proj2: alpha=0.1</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.900935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LassoRegression(Bagging)</td>\n",
       "      <td>From Proj2: alpha=0.01</td>\n",
       "      <td>0.921194</td>\n",
       "      <td>0.946404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVR(Pasting)</td>\n",
       "      <td>From Proj2: C=1000</td>\n",
       "      <td>0.922910</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KernelSVR(Pasting)</td>\n",
       "      <td>From Proj2: C=10,gamma=0.1</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTree(Adaboost)</td>\n",
       "      <td>{'base_estimator__max_depth': 12}</td>\n",
       "      <td>0.992776</td>\n",
       "      <td>0.879385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression(Adaboost)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722812</td>\n",
       "      <td>0.756270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.979853</td>\n",
       "      <td>0.865416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model                              Best Parameters  \\\n",
       "0    RidgeRegression(Bagging)                        From Proj2: alpha=0.1   \n",
       "1    LassoRegression(Bagging)                       From Proj2: alpha=0.01   \n",
       "2          LinearSVR(Pasting)                           From Proj2: C=1000   \n",
       "3          KernelSVR(Pasting)                   From Proj2: C=10,gamma=0.1   \n",
       "4             DTree(Adaboost)            {'base_estimator__max_depth': 12}   \n",
       "5  LinearRegression(Adaboost)                                          NaN   \n",
       "6   GradientBoostingRegressor  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "   Train accuracy  Test accuracy  \n",
       "0        0.894924       0.900935  \n",
       "1        0.921194       0.946404  \n",
       "2        0.922910       0.940000  \n",
       "3       -0.059582      -0.043834  \n",
       "4        0.992776       0.879385  \n",
       "5        0.722812       0.756270  \n",
       "6        0.979853       0.865416  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_tabledf = pd.read_csv('RegressionReport_Project3.csv')\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Applied Models and Comparison with Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Parameters from Project2</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train accuracy Project2</th>\n",
       "      <th>Test accuracy Project2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression(PCA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943914</td>\n",
       "      <td>0.965617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeRegression(PCA)</td>\n",
       "      <td>alpha=0.1</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892767</td>\n",
       "      <td>0.943151</td>\n",
       "      <td>0.964527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoRegression(PCA)</td>\n",
       "      <td>alpha=0.01</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.892765</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.965217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVR(PCA)</td>\n",
       "      <td>C=1000</td>\n",
       "      <td>0.860143</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>0.933516</td>\n",
       "      <td>0.957628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KernelSVR(PCA)</td>\n",
       "      <td>C=10; gamma=0.1</td>\n",
       "      <td>0.195885</td>\n",
       "      <td>0.137391</td>\n",
       "      <td>0.586894</td>\n",
       "      <td>0.418031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNNRegression(PCA)</td>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.947255</td>\n",
       "      <td>0.857080</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.839912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PolynomialRegression(PCA)</td>\n",
       "      <td>Trial: Degree=2</td>\n",
       "      <td>0.932155</td>\n",
       "      <td>0.922674</td>\n",
       "      <td>0.943914</td>\n",
       "      <td>0.965617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Best Parameters from Project2  Train accuracy  \\\n",
       "0      LinearRegression(PCA)                           NaN        0.897009   \n",
       "1       RidgeRegression(PCA)                     alpha=0.1        0.897009   \n",
       "2       LassoRegression(PCA)                    alpha=0.01        0.897009   \n",
       "3             LinearSVR(PCA)                        C=1000        0.860143   \n",
       "4             KernelSVR(PCA)               C=10; gamma=0.1        0.195885   \n",
       "5         KNNRegression(PCA)                 n_neighbors=3        0.947255   \n",
       "6  PolynomialRegression(PCA)               Trial: Degree=2        0.932155   \n",
       "\n",
       "   Test accuracy  Train accuracy Project2  Test accuracy Project2  \n",
       "0       0.892767                 0.943914                0.965617  \n",
       "1       0.892767                 0.943151                0.964527  \n",
       "2       0.892765                 0.942931                0.965217  \n",
       "3       0.851986                 0.933516                0.957628  \n",
       "4       0.137391                 0.586894                0.418031  \n",
       "5       0.857080                 0.953086                0.839912  \n",
       "6       0.922674                 0.943914                0.965617  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_tabledf = pd.read_csv('RegressionReport_PCA_Project3.csv')\n",
    "report_tabledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firsty this regression exercise is an extension of the findings of project 2. We have explored the dataset, there are no missing values and no categorical variables. For ensemble modelling, like all the individual regression models, we have done MinMaxScaler and before PCA we have have used StandardScaler - the reason is we wanted to transform the data to zero mean and unit variance. After PCA decomposition, 77 features are reduced to 18 principal components.\n",
    "\n",
    "After the reduced data is fed into the models after PCA decomposition, from the results we can see that for Linear, Ridge and Lasso Regression the training and testing score are almost the same and all three are a fair fit. Now the reduction in accuracy may be attributed to the fact that the underlying sampling data might have changed from Project 2 to Project 3 - i.e. the 10% sample of Project 2 is slightly different from Project 3.\n",
    "\n",
    "The best model after application of PCA seems to be KNNRegressor which has the highest training and test accuracy. Defnitely after the application of PCA, the results of KNNRegressor are slightly better as Training score and Testing score are more closer.\n",
    "\n",
    "Among the Ensemble models, Adaboosting Decision Tree with maximum depth = 12 seems to be the best but it seems to be slightly overfitted due to the gap between training and testing score.\n",
    "\n",
    "The next best ensemble model is LinearSVR pasting due to closeness of Training and Test score.\n",
    "\n",
    "We tried to implement two Deep Learning models by arranging different node layers, but both of them gave a very high mean-square error, hence we have discarded the deep learning models from our consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
